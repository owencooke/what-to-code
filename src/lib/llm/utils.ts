import { llm } from "./config";
import { z } from "zod";
import { PromptTemplate } from "@langchain/core/prompts";

/**
 * Generates a structured LLM response based on a Zod schema from a given prompt string.
 * It supports both object and array schemas. If the schema
 *
 * @template T - The type of the output schema.
 * @param {z.ZodSchema<T>} outputSchema - The Zod schema that defines the structure of the LLM output.
 * @param {string} promptString - The prompt string to be used by the LLM.
 * @param {Record<string, any>} [promptVars] - Optional variables to be injected into prompt template {variables}.
 * @returns {Promise<T>} - A promise that resolves to the structured output generated by the LLM.
 * @throws {Error} - Throws an error if the LLM does not support structured output.
 *
 * @example
 * const schema = z.object({
 *   name: z.string(),
 *   age: z.number(),
 * });
 * const prompt = "Generate a person object with name and age.";
 * const result = await generateZodSchemaFromPrompt(schema, prompt);
 * console.log(result); // { name: "John Doe", age: 30 }
 */
async function generateZodSchemaFromPrompt<T>(
  outputSchema: z.ZodSchema<T>,
  promptString: string,
  promptVars?: Record<string, any>,
): Promise<T> {
  if (!llm.withStructuredOutput) {
    throw new Error(
      `withStructuredOutput is not available for model: ${process.env.LLM_MODEL}`,
    );
  }

  // Check if the schema is an array and wrap it in an object schema if necessary
  const isArray = outputSchema instanceof z.ZodArray;
  const wrappedSchema = isArray
    ? z.object({ items: outputSchema })
    : outputSchema;

  const result = await llm
    .withStructuredOutput(wrappedSchema)
    .invoke(
      await PromptTemplate.fromTemplate(promptString).invoke(promptVars || {}),
    );

  return isArray ? result.items : result;
}

export { generateZodSchemaFromPrompt };
